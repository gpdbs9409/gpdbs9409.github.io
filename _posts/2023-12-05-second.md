---
layout: post
title: beautiful soup
---


크롤링에서 젤 많이 이용된다고 하는 beautifulsoup4 라이브러리를 이용해보았다

```python
from urllib.request import urlopen

from bs4 import BeautifulSoup 

html = urlopen("<https://news.naver.com/>")

bsObject = BeautifulSoup(html, "html.parser") [#for](<https://www.youtube.com/hashtag/for>) link in bsObject.find_all('a'):

 # print(link.text.strip(), link.get('href')) 

for link in bsObject.find_all('img'): print(link.text.strip(), link.get('src'))
```

코드는 요렇게 했다 . urlopen 이거는 url 열어주는 소스고 beautifulsoup 이거는 , html 받아서 html접근하게 해주는 소스이다 . 일단 상권분석에서 긁어와야 하는 태그는 뭔지 이따가 보기로 하고 , 네이버뉴스 url 에서 link 데이터들(href 태그로 시작하는 애들)을 긁어와 봤다 .

첨에는 beatifulsoup 이거가 모듈 에러가 있었다 .

[https://studyhard24.tistory.com/234](https://studyhard24.tistory.com/234)

여기에 나온대로 cmd 를 이용해서 python script에다가 pip install beautifulsoup4를 하니까 바로 되었다

오 . 네이버 뉴스 사이트 에서 링크들이 긁어져왔다 .

[crawling_1.py](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/bcb4cadc-fd32-4752-bc8d-7258ecf87afb/crawling_1.py)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5ee28c39-cb99-464b-91b7-92efa609c7a8/Untitled.png)

이런식으로 , , 그렇다면 이제 HTML 을 이용해서 내가 상권분석 사이트인

[https://golmok.seoul.go.kr/commercialArea/commercialArea.do#](https://golmok.seoul.go.kr/commercialArea/commercialArea.do#)

여기 HTML 을보고 여기서 어떤 데이터 타입을 긁어와야하는지 판단해야할 것 같다 .

